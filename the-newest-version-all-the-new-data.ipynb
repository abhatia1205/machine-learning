{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6197af3f-fe84-4e2f-91c4-0b09a8850726",
    "_uuid": "14d4521dafb4e37d3f78bd90b09a8a3090c70130"
   },
   "source": [
    "# Fitting a Model With Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c4e1bbbef576fde56ed1386c9fb87f78cf59df23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'V', 'Q', 'I', 'N', 'W', 'D', 'C', 'A', 'E', 'X', 'Y', 'K', 'O', 'L', 'P', 'R', 'B', 'G', 'M', 'H', 'U', 'S', 'T']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input/backupasl/asl train set/ASL Train Set\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "48880593-9f58-4bce-b534-9cde1410d87e",
    "_uuid": "f1ffff5bbc85908dbea5e10c7b143000f04f3f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60667 images belonging to 24 classes.\n",
      "Found 25985 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "data_generator_with_aug = ImageDataGenerator(\n",
    "                                    samplewise_center=True, \n",
    "                                    samplewise_std_normalization=True,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   validation_split = 0.3, rotation_range = 10,\n",
    "                                   zoom_range = 0.1)\n",
    "\n",
    "\n",
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/backupasl/asl train set/ASL Train Set\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/backupasl/asl train set/ASL Train Set\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbec1b168a9dcc98d0785f2bc3cd16f32b89cb1d"
   },
   "source": [
    "The dataset these train generators use seem to have a lot of faulty data. I printed some out, and they dont look like hands. Wont be used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb2a43bac520fa71122674a1f4811001147e3093"
   },
   "source": [
    "train_generator2 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-alphabet-test/asl-alphabet-test\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator2 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-alphabet-test/asl-alphabet-test\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n",
    "\n",
    "\n",
    "train_generator3 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/A\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator3 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/A\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n",
    "train_generator4 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/B\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator4 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/B\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n",
    "\n",
    "\n",
    "train_generator5 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/C\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator5 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/C\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n",
    "train_generator6 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/D\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator6 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/D\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n",
    "\n",
    "\n",
    "train_generator7 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/E\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "\n",
    "validation_generator7 = data_generator_with_aug.flow_from_directory(\n",
    "        \"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/E\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9005381d57506241e9d90e3f966508b2f6e3556a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "num_classes = 24\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "my_model = Sequential()\n",
    "conv_test = Conv2D(64, kernel_size=4, strides=1, activation='sigmoid', input_shape=(image_size, image_size, 3))\n",
    "my_model.add(conv_test)\n",
    "my_model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
    "my_model.add(Dropout(0.5))\n",
    "my_model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))\n",
    "my_model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))\n",
    "my_model.add(Dropout(0.5))\n",
    "my_model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))\n",
    "my_model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dropout(0.5))\n",
    "my_model.add(Dense(512, activation='relu'))\n",
    "my_model.add(Dense(num_classes, activation='softmax'))\n",
    "my_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c10e2057e16367c418b85feda3629ace6c04e275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1000/1000 [==============================] - 428s 428ms/step - loss: 2.7405 - acc: 0.1712 - val_loss: 1.8271 - val_acc: 0.4959\n",
      "Epoch 2/7\n",
      "1000/1000 [==============================] - 412s 412ms/step - loss: 1.1126 - acc: 0.6368 - val_loss: 0.9787 - val_acc: 0.7668\n",
      "Epoch 3/7\n",
      "1000/1000 [==============================] - 411s 411ms/step - loss: 0.5300 - acc: 0.8214 - val_loss: 0.6932 - val_acc: 0.8476\n",
      "Epoch 4/7\n",
      "1000/1000 [==============================] - 403s 403ms/step - loss: 0.3169 - acc: 0.8934 - val_loss: 0.7985 - val_acc: 0.8963\n",
      "Epoch 5/7\n",
      "1000/1000 [==============================] - 405s 405ms/step - loss: 0.2053 - acc: 0.9307 - val_loss: 0.8107 - val_acc: 0.8452\n",
      "Epoch 6/7\n",
      "1000/1000 [==============================] - 402s 402ms/step - loss: 0.1533 - acc: 0.9476 - val_loss: 0.3983 - val_acc: 0.9290\n",
      "Epoch 7/7\n",
      "  82/1000 [=>............................] - ETA: 2:40 - loss: 0.1030 - acc: 0.9649"
     ]
    }
   ],
   "source": [
    "my_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=7,\n",
    "        validation_data=validation_generator, validation_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "af75b9a0e71e0194b85bb667dc55c06b38c33508"
   },
   "outputs": [],
   "source": [
    "my_model.save(\"model3.h5py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8905e336caeff6fc95fef716f205d04c01a47e0"
   },
   "source": [
    "my_new_model.fit_generator(\n",
    "        train_generator3,\n",
    "        steps_per_epoch=500,\n",
    "        epochs=6,\n",
    "        validation_data=validation_generator3, validation_steps = 500)0.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19f9fe8182297d64c52f96a0d537d864c4545618"
   },
   "source": [
    "my_new_model.fit_generator(\n",
    "        train_generator4,\n",
    "        steps_per_epoch=500,\n",
    "        epochs=6,\n",
    "        validation_data=validation_generator4, validation_steps = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e25e54ca859aa6d363f1e94aff2fda111640ef93"
   },
   "source": [
    "my_new_model.fit_generator(\n",
    "        train_generator5,\n",
    "        steps_per_epoch=500,\n",
    "        epochs=6,\n",
    "        validation_data=validation_generator5, validation_steps = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc3e98be5be0e5a52776bd2cd3ee59930edcf37a"
   },
   "source": [
    "data_generator_with_aug2 = ImageDataGenerator(\n",
    "                                    samplewise_center=True, \n",
    "                                    samplewise_std_normalization=True,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   validation_split = 0.4, rotation_range = 10,\n",
    "                                   zoom_range = 0.1)\n",
    "test_generator = data_generator_with_aug2.flow_from_directory(\n",
    "        \"../input/sohandatasetnew/augmented asl 3 -sohan dataset/Augmented ASL 3 -Sohan Dataset\",\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical', subset = 'training')\n",
    "validation_generator213 = data_generator_with_aug2.flow_from_directory(\n",
    "        \"../input/sohandatasetnew/augmented asl 3 -sohan dataset/Augmented ASL 3 -Sohan Dataset\",\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical', subset = 'validation')\n",
    "my_new_model.fit_generator(\n",
    "        test_generator,\n",
    "        steps_per_epoch=500,\n",
    "        epochs=6,\n",
    "        validation_data=validation_generator213, validation_steps = 500)\n",
    "\n",
    "\n",
    "print(my_new_model.evaluate_generator(vaildation_generator213))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b8a47066e2f7b8e3b0f1fa4d9f8026d87330563"
   },
   "source": [
    "**DATA VISUALIZATION METHODS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4af56e9ef32c75ac3e45c1ba6c6e15b32da8f5da"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "c=0\n",
    "for i in os.listdir(\"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/C/a\"):\n",
    "    if c < 5:\n",
    "        image = mpimg.imread(\"../input/asl-rgb-depth-fingerspelling-spelling-it-out/fingerspelling5/dataset5/C/a\"+\"/\"+i)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    else:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4705e635dbab76d9b8812150bb2d1da642c566cb"
   },
   "source": [
    "from random import shuffle\n",
    "import cv2\n",
    "def shuffling(a, b):\n",
    "    arr = []\n",
    "    c = list(zip(a, b))\n",
    "    shuffle(c)\n",
    "    a, b = zip(*c)\n",
    "    arr.append(a)\n",
    "    arr.append(b)\n",
    "    return arr\n",
    "import os\n",
    "from matplotlib.image import imread \n",
    "def test_x_y(input_directory):\n",
    "    x = []\n",
    "    y =[]\n",
    "    for i in os.listdir(input_directory):\n",
    "        for j in os.listdir(input_directory+\"/\"+i):\n",
    "            x.append(cv2.imread(input_directory+\"/\"+i+\"/\"+j))\n",
    "            y.append(i)\n",
    "    return[x,y]\n",
    "a = test_x_y(\"../input/sohan-dataset-new/augmented asl 3/Augmented ASL 3\")\n",
    "xl,yl = a[0],a[1]\n",
    "test_arr = shuffling(xl,yl)\n",
    "x, y = list(test_arr[0]), list(test_arr[1])\n",
    "type(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a68f3b83028b8dc7f8466d44965fdec48df8ee4"
   },
   "source": [
    "image_trial = cv2.resize(x[0], (64,64))\n",
    "plt.imshow(image_trial)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b708bfdd1d4bcb8272112fbdf6607e554624413b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "069179b379e964201f80d1ffa4b0a0ff8e554a90"
   },
   "source": [
    "conv_test.get_input_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "eec0f2e93b25e5c794e572cea7636a59d2dac8cb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
